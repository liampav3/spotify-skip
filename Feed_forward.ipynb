{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these lines at the end of data-preparation to get clipped_data.csv\n",
    "data = data[data.session_id <= 20000]\n",
    "data.drop(['hist_user_behavior_reason_end', 'skip_1', 'skip_2', 'skip_3', 'session_id'], axis=1, inplace=True)\n",
    "data.to_csv('./data/clipped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_position</th>\n",
       "      <th>session_length</th>\n",
       "      <th>context_switch</th>\n",
       "      <th>no_pause_before_play</th>\n",
       "      <th>short_pause_before_play</th>\n",
       "      <th>long_pause_before_play</th>\n",
       "      <th>hist_user_behavior_n_seekfwd</th>\n",
       "      <th>hist_user_behavior_n_seekback</th>\n",
       "      <th>hist_user_behavior_is_shuffle</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>acoustic_vector_0</th>\n",
       "      <th>acoustic_vector_1</th>\n",
       "      <th>acoustic_vector_2</th>\n",
       "      <th>acoustic_vector_3</th>\n",
       "      <th>acoustic_vector_4</th>\n",
       "      <th>acoustic_vector_5</th>\n",
       "      <th>acoustic_vector_6</th>\n",
       "      <th>acoustic_vector_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12575</th>\n",
       "      <td>-1.429275</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>-1.578338</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>0.968958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-0.975873</td>\n",
       "      <td>-0.431383</td>\n",
       "      <td>0.514973</td>\n",
       "      <td>0.951803</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>-0.617304</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>-0.135089</td>\n",
       "      <td>0.057216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139988</th>\n",
       "      <td>0.413331</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>0.633578</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>1.469694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>1.802820</td>\n",
       "      <td>-0.316789</td>\n",
       "      <td>0.972022</td>\n",
       "      <td>1.589783</td>\n",
       "      <td>0.923791</td>\n",
       "      <td>0.973468</td>\n",
       "      <td>0.487320</td>\n",
       "      <td>2.403868</td>\n",
       "      <td>0.134691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56216</th>\n",
       "      <td>1.518894</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>0.633578</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>0.134397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>0.617122</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>0.370938</td>\n",
       "      <td>-0.174786</td>\n",
       "      <td>-1.263426</td>\n",
       "      <td>0.901582</td>\n",
       "      <td>0.819490</td>\n",
       "      <td>-0.750319</td>\n",
       "      <td>-1.698549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120888</th>\n",
       "      <td>-1.429275</td>\n",
       "      <td>0.089332</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>-1.578338</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>2.618657</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>0.134397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-0.771903</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>-0.967778</td>\n",
       "      <td>-1.263611</td>\n",
       "      <td>-0.887162</td>\n",
       "      <td>1.163613</td>\n",
       "      <td>0.887784</td>\n",
       "      <td>-0.625656</td>\n",
       "      <td>-0.538548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97730</th>\n",
       "      <td>0.044810</td>\n",
       "      <td>-0.206974</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>-1.578338</td>\n",
       "      <td>2.471831</td>\n",
       "      <td>2.243759</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>-0.700163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-1.079259</td>\n",
       "      <td>-0.735213</td>\n",
       "      <td>0.046869</td>\n",
       "      <td>-0.269483</td>\n",
       "      <td>0.485190</td>\n",
       "      <td>-0.528858</td>\n",
       "      <td>-0.629586</td>\n",
       "      <td>-0.607584</td>\n",
       "      <td>0.485332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30451</th>\n",
       "      <td>1.887415</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>0.633578</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>0.968958</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.874445</td>\n",
       "      <td>-0.956179</td>\n",
       "      <td>2.451101</td>\n",
       "      <td>-2.680631</td>\n",
       "      <td>-2.459658</td>\n",
       "      <td>-0.977732</td>\n",
       "      <td>0.308548</td>\n",
       "      <td>0.531793</td>\n",
       "      <td>0.257052</td>\n",
       "      <td>0.012089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152556</th>\n",
       "      <td>0.044810</td>\n",
       "      <td>-1.095892</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>0.633578</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>-0.032515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-0.470161</td>\n",
       "      <td>-0.909802</td>\n",
       "      <td>0.541354</td>\n",
       "      <td>0.691299</td>\n",
       "      <td>0.273945</td>\n",
       "      <td>-0.600785</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>-0.531294</td>\n",
       "      <td>0.359749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>0.044810</td>\n",
       "      <td>-0.206974</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>-1.578338</td>\n",
       "      <td>2.471831</td>\n",
       "      <td>2.243759</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>1.529961</td>\n",
       "      <td>1.469694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-1.838737</td>\n",
       "      <td>2.104809</td>\n",
       "      <td>-2.341289</td>\n",
       "      <td>-2.487015</td>\n",
       "      <td>0.333201</td>\n",
       "      <td>-0.475326</td>\n",
       "      <td>-1.218144</td>\n",
       "      <td>1.432851</td>\n",
       "      <td>1.064619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68106</th>\n",
       "      <td>0.044810</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>0.633578</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>-0.700163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>0.988427</td>\n",
       "      <td>1.247781</td>\n",
       "      <td>-1.600237</td>\n",
       "      <td>0.380791</td>\n",
       "      <td>0.892728</td>\n",
       "      <td>0.488825</td>\n",
       "      <td>-1.458435</td>\n",
       "      <td>1.523461</td>\n",
       "      <td>-2.365966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152190</th>\n",
       "      <td>-1.429275</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>-0.218647</td>\n",
       "      <td>-1.578338</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.134574</td>\n",
       "      <td>-0.115693</td>\n",
       "      <td>-0.653611</td>\n",
       "      <td>0.968958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149062</td>\n",
       "      <td>-1.331645</td>\n",
       "      <td>-0.735474</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.245956</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.192121</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>-0.350035</td>\n",
       "      <td>0.503042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86979 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_position  session_length  context_switch  \\\n",
       "12575          -1.429275        0.681944       -0.218647   \n",
       "139988          0.413331        0.681944       -0.218647   \n",
       "56216           1.518894        0.681944       -0.218647   \n",
       "120888         -1.429275        0.089332       -0.218647   \n",
       "97730           0.044810       -0.206974       -0.218647   \n",
       "...                  ...             ...             ...   \n",
       "30451           1.887415        0.681944       -0.218647   \n",
       "152556          0.044810       -1.095892       -0.218647   \n",
       "5452            0.044810       -0.206974       -0.218647   \n",
       "68106           0.044810        0.681944       -0.218647   \n",
       "152190         -1.429275        0.681944       -0.218647   \n",
       "\n",
       "        no_pause_before_play  short_pause_before_play  long_pause_before_play  \\\n",
       "12575              -1.578338                -0.404558               -0.445681   \n",
       "139988              0.633578                -0.404558               -0.445681   \n",
       "56216               0.633578                -0.404558               -0.445681   \n",
       "120888             -1.578338                -0.404558               -0.445681   \n",
       "97730              -1.578338                 2.471831                2.243759   \n",
       "...                      ...                      ...                     ...   \n",
       "30451               0.633578                -0.404558               -0.445681   \n",
       "152556              0.633578                -0.404558               -0.445681   \n",
       "5452               -1.578338                 2.471831                2.243759   \n",
       "68106               0.633578                -0.404558               -0.445681   \n",
       "152190             -1.578338                -0.404558               -0.445681   \n",
       "\n",
       "        hist_user_behavior_n_seekfwd  hist_user_behavior_n_seekback  \\\n",
       "12575                      -0.134574                      -0.115693   \n",
       "139988                     -0.134574                      -0.115693   \n",
       "56216                      -0.134574                      -0.115693   \n",
       "120888                      2.618657                      -0.115693   \n",
       "97730                      -0.134574                      -0.115693   \n",
       "...                              ...                            ...   \n",
       "30451                      -0.134574                      -0.115693   \n",
       "152556                     -0.134574                      -0.115693   \n",
       "5452                       -0.134574                      -0.115693   \n",
       "68106                      -0.134574                      -0.115693   \n",
       "152190                     -0.134574                      -0.115693   \n",
       "\n",
       "        hist_user_behavior_is_shuffle  hour_of_day  ...  time_signature  \\\n",
       "12575                       -0.653611     0.968958  ...        0.149062   \n",
       "139988                      -0.653611     1.469694  ...        0.149062   \n",
       "56216                       -0.653611     0.134397  ...        0.149062   \n",
       "120888                      -0.653611     0.134397  ...        0.149062   \n",
       "97730                       -0.653611    -0.700163  ...        0.149062   \n",
       "...                               ...          ...  ...             ...   \n",
       "30451                       -0.653611     0.968958  ...       -2.874445   \n",
       "152556                      -0.653611    -0.032515  ...        0.149062   \n",
       "5452                         1.529961     1.469694  ...        0.149062   \n",
       "68106                       -0.653611    -0.700163  ...        0.149062   \n",
       "152190                      -0.653611     0.968958  ...        0.149062   \n",
       "\n",
       "         valence  acoustic_vector_0  acoustic_vector_1  acoustic_vector_2  \\\n",
       "12575  -0.975873          -0.431383           0.514973           0.951803   \n",
       "139988  1.802820          -0.316789           0.972022           1.589783   \n",
       "56216   0.617122           0.873800           0.370938          -0.174786   \n",
       "120888 -0.771903           0.849128          -0.967778          -1.263611   \n",
       "97730  -1.079259          -0.735213           0.046869          -0.269483   \n",
       "...          ...                ...                ...                ...   \n",
       "30451  -0.956179           2.451101          -2.680631          -2.459658   \n",
       "152556 -0.470161          -0.909802           0.541354           0.691299   \n",
       "5452   -1.838737           2.104809          -2.341289          -2.487015   \n",
       "68106   0.988427           1.247781          -1.600237           0.380791   \n",
       "152190 -1.331645          -0.735474           0.792431           0.245956   \n",
       "\n",
       "        acoustic_vector_3  acoustic_vector_4  acoustic_vector_5  \\\n",
       "12575            0.003519          -0.617304           0.470500   \n",
       "139988           0.923791           0.973468           0.487320   \n",
       "56216           -1.263426           0.901582           0.819490   \n",
       "120888          -0.887162           1.163613           0.887784   \n",
       "97730            0.485190          -0.528858          -0.629586   \n",
       "...                   ...                ...                ...   \n",
       "30451           -0.977732           0.308548           0.531793   \n",
       "152556           0.273945          -0.600785           0.054287   \n",
       "5452             0.333201          -0.475326          -1.218144   \n",
       "68106            0.892728           0.488825          -1.458435   \n",
       "152190          -0.050978          -0.192121           0.024652   \n",
       "\n",
       "        acoustic_vector_6  acoustic_vector_7  \n",
       "12575           -0.135089           0.057216  \n",
       "139988           2.403868           0.134691  \n",
       "56216           -0.750319          -1.698549  \n",
       "120888          -0.625656          -0.538548  \n",
       "97730           -0.607584           0.485332  \n",
       "...                   ...                ...  \n",
       "30451            0.257052           0.012089  \n",
       "152556          -0.531294           0.359749  \n",
       "5452             1.432851           1.064619  \n",
       "68106            1.523461          -2.365966  \n",
       "152190          -0.350035           0.503042  \n",
       "\n",
       "[86979 rows x 42 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/clipped_data.csv')\n",
    "y = raw_data['not_skipped']\n",
    "raw_data.drop(['not_skipped', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "columns = raw_data.columns\n",
    "raw_data = pd.DataFrame(StandardScaler().fit_transform(raw_data), columns=columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_data, y, test_size = 0.25, shuffle = True, random_state= 2001)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3, shuffle = True, random_state= 2022)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "165671    1.0\n",
       "165672    1.0\n",
       "165673    0.0\n",
       "165674    0.0\n",
       "165675    0.0\n",
       "Name: not_skipped, Length: 165676, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_idx_tmp = np.array(self.X.iloc[idx])\n",
    "        y_idx_tmp = np.array(self.y.iloc[idx])\n",
    "\n",
    "        return torch.Tensor(x_idx_tmp), torch.Tensor(y_idx_tmp) \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data = SkipDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "test_data = SkipDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "val_data = SkipDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(42, 1, 32)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.00001)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 \t Loss: 441.2876 \t Avg. Validation Batch Accuracy: 0.6724 \n",
      "Epoch: 305 \t Loss: 440.9867 \t Avg. Validation Batch Accuracy: 0.6718 \n",
      "Epoch: 310 \t Loss: 440.6675 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 315 \t Loss: 440.3692 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 320 \t Loss: 440.0839 \t Avg. Validation Batch Accuracy: 0.6722 \n",
      "Epoch: 325 \t Loss: 439.7990 \t Avg. Validation Batch Accuracy: 0.6723 \n",
      "Epoch: 330 \t Loss: 439.4886 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 335 \t Loss: 439.2468 \t Avg. Validation Batch Accuracy: 0.6722 \n",
      "Epoch: 340 \t Loss: 438.9582 \t Avg. Validation Batch Accuracy: 0.6722 \n",
      "Epoch: 345 \t Loss: 438.7178 \t Avg. Validation Batch Accuracy: 0.6717 \n",
      "Epoch: 350 \t Loss: 438.4712 \t Avg. Validation Batch Accuracy: 0.6718 \n",
      "Epoch: 355 \t Loss: 438.2049 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 360 \t Loss: 437.9693 \t Avg. Validation Batch Accuracy: 0.6725 \n",
      "Epoch: 365 \t Loss: 437.7345 \t Avg. Validation Batch Accuracy: 0.6720 \n",
      "Epoch: 370 \t Loss: 437.5151 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 375 \t Loss: 437.2739 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 380 \t Loss: 437.0385 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 385 \t Loss: 436.8306 \t Avg. Validation Batch Accuracy: 0.6722 \n",
      "Epoch: 390 \t Loss: 436.5969 \t Avg. Validation Batch Accuracy: 0.6724 \n",
      "Epoch: 395 \t Loss: 436.4113 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 400 \t Loss: 436.2129 \t Avg. Validation Batch Accuracy: 0.6723 \n",
      "Epoch: 405 \t Loss: 436.0289 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 410 \t Loss: 435.8149 \t Avg. Validation Batch Accuracy: 0.6724 \n",
      "Epoch: 415 \t Loss: 435.6044 \t Avg. Validation Batch Accuracy: 0.6723 \n",
      "Epoch: 420 \t Loss: 435.4149 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 425 \t Loss: 435.2189 \t Avg. Validation Batch Accuracy: 0.6720 \n",
      "Epoch: 430 \t Loss: 435.0362 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 435 \t Loss: 434.8909 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 440 \t Loss: 434.6917 \t Avg. Validation Batch Accuracy: 0.6722 \n",
      "Epoch: 445 \t Loss: 434.5187 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 450 \t Loss: 434.3391 \t Avg. Validation Batch Accuracy: 0.6726 \n",
      "Epoch: 455 \t Loss: 434.1840 \t Avg. Validation Batch Accuracy: 0.6724 \n",
      "Epoch: 460 \t Loss: 433.9975 \t Avg. Validation Batch Accuracy: 0.6726 \n",
      "Epoch: 465 \t Loss: 433.8634 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 470 \t Loss: 433.6942 \t Avg. Validation Batch Accuracy: 0.6721 \n",
      "Epoch: 475 \t Loss: 433.5375 \t Avg. Validation Batch Accuracy: 0.6723 \n",
      "Epoch: 480 \t Loss: 433.3610 \t Avg. Validation Batch Accuracy: 0.6718 \n",
      "Epoch: 485 \t Loss: 433.2333 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 490 \t Loss: 433.0920 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 495 \t Loss: 432.9629 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 500 \t Loss: 432.8081 \t Avg. Validation Batch Accuracy: 0.6719 \n",
      "Epoch: 505 \t Loss: 432.6777 \t Avg. Validation Batch Accuracy: 0.6725 \n",
      "Epoch: 510 \t Loss: 432.5190 \t Avg. Validation Batch Accuracy: 0.6723 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/noah/Desktop/Machine Learning/final project/Feed_forward.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000007?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m, epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000007?line=3'>4</a>\u001b[0m     epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000007?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (x_inst, y_inst) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000007?line=7'>8</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000007?line=9'>10</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mforward(x_inst)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/Users/noah/Desktop/Machine Learning/final project/Feed_forward.ipynb Cell 4'\u001b[0m in \u001b[0;36mSkipDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000002?line=9'>10</a>\u001b[0m     x_idx_tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX\u001b[39m.\u001b[39miloc[idx])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000002?line=10'>11</a>\u001b[0m     y_idx_tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my\u001b[39m.\u001b[39;49miloc[idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000002?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mTensor(x_idx_tmp), torch\u001b[39m.\u001b[39mTensor(y_idx_tmp)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_statement = \"Epoch: {} \\t Loss: {:.4f} \\t Avg. Validation Batch Accuracy: {:.4f} \"\n",
    "\n",
    "for epoch in range(300, epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (x_inst, y_inst) in enumerate(train_dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = net.forward(x_inst)\n",
    "        cost = criterion(y_pred, y_inst.reshape(-1, 1))\n",
    "\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += cost.abs().item()\n",
    "\n",
    "    costs.append(epoch_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        n_batches = 0\n",
    "        running_acc = 0\n",
    "        for i, (x_val_inst, y_val_inst) in enumerate(val_dataloader):\n",
    "            n_batches += 1\n",
    "            y_val_pred = net.forward(x_val_inst).sigmoid().round()\n",
    "            running_acc += accuracy_score(y_val_inst.detach().numpy(), y_val_pred.detach().numpy())\n",
    "\n",
    "            \n",
    "        print(print_statement.format(epoch, epoch_loss, running_acc / n_batches))\n",
    "\n",
    "        torch.save(net.state_dict(), f\"./saved_models/feed_forward_{epoch}.pt\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 679 \t Accuracy: 0.6714068651199341\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for x_inst, y_inst in test_data:\n",
    "    y_pred = net.forward(x_inst)\n",
    "    correct += (1 - (y_pred.sigmoid().round() - y_inst).abs()).abs()\n",
    "\n",
    "acc = (correct / len(test_data)).item()\n",
    "print(f\"Epoch: {i} \\t Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/noah/Desktop/Machine Learning/final project/Feed_forward.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000008?line=3'>4</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000008?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m x_inst, y_inst \u001b[39min\u001b[39;00m test_data:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000008?line=5'>6</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(x_inst)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000008?line=6'>7</a>\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (y_pred\u001b[39m.\u001b[39msigmoid()\u001b[39m.\u001b[39mround() \u001b[39m-\u001b[39m y_inst)\u001b[39m.\u001b[39mabs())\u001b[39m.\u001b[39mabs()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000008?line=8'>9</a>\u001b[0m acc \u001b[39m=\u001b[39m (correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_data))\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32m/Users/noah/Desktop/Machine Learning/final project/Feed_forward.ipynb Cell 6'\u001b[0m in \u001b[0;36mFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000004?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000004?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for i in range(0, 265, 5):\n",
    "    net.load_state_dict(torch.load(f'./saved_models/feed_forward_{i}.pt'))\n",
    "    correct = 0\n",
    "    for x_inst, y_inst in test_data:\n",
    "        y_pred = net.forward(x_inst)\n",
    "        correct += (1 - (y_pred.sigmoid().round() - y_inst).abs()).abs()\n",
    "\n",
    "    acc = (correct / len(test_data)).item()\n",
    "    print(f\"Epoch: {i} \\t Accuracy: {acc}\")\n",
    "    accs.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2733489154115508\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/noah/Desktop/Machine Learning/final project/Feed_forward.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000011?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/noah/Desktop/Machine%20Learning/final%20project/Feed_forward.ipynb#ch0000011?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(costs)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py?line=2754'>2755</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py?line=2755'>2756</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py?line=2756'>2757</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py?line=2757'>2758</a>\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/pyplot.py?line=2758'>2759</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1389'>1390</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1390'>1391</a>\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1391'>1392</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1628'>1629</a>\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1629'>1630</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1630'>1631</a>\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1631'>1632</a>\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1632'>1633</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py?line=1633'>1634</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=309'>310</a>\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=310'>311</a>\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=311'>312</a>\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py:490\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=487'>488</a>\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=488'>489</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=489'>490</a>\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=491'>492</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/axes/_base.py?line=492'>493</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mupdate_units(x)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1652\u001b[0m, in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1649'>1650</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1650'>1651</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1651'>1652</a>\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(y)\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1652'>1653</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (np\u001b[39m.\u001b[39mVisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1653'>1654</a>\u001b[0m     \u001b[39m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1654'>1655</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1304\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1301'>1302</a>\u001b[0m \u001b[39m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1302'>1303</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1303'>1304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1304'>1305</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1305'>1306</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1306'>1307</a>\u001b[0m         \u001b[39m# work around\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1307'>1308</a>\u001b[0m         \u001b[39m# https://github.com/pandas-dev/pandas/issues/27775 which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1318'>1319</a>\u001b[0m         \u001b[39m# This code should correctly identify and coerce to a\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/matplotlib/cbook/__init__.py?line=1319'>1320</a>\u001b[0m         \u001b[39m# numpy array all pandas versions.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py?line=62'>63</a>\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[0;32m---> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py?line=64'>65</a>\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py?line=65'>66</a>\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py?line=66'>67</a>\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Machine Learning/final project/.venv/lib/python3.8/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/_tensor.py?line=729'>730</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/_tensor.py?line=730'>731</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/_tensor.py?line=731'>732</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/_tensor.py?line=732'>733</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/noah/Desktop/Machine%20Learning/final%20project/.venv/lib/python3.8/site-packages/torch/_tensor.py?line=733'>734</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5078125"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1,  1, -1, -1,  1])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29f4812d33dadcad0b37f309456ecf77aa32337c1bd8abfea0be004ece206f45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
